{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19a33b0",
   "metadata": {},
   "source": [
    "# Kaggle InsightFace Remote Embedding Service\n",
    "This notebook sets up a FastAPI server providing remote embedding & similarity operations using a GPU (2x T4) environment. You can tunnel the service to your local machine and keep raw video data local.\n",
    "\n",
    "Steps:\n",
    "1. Install dependencies (skip if already present).\n",
    "2. (Optional) Enable Cloudflare tunnel for external access.\n",
    "3. Launch FastAPI server (non-blocking).\n",
    "4. Test endpoints from within notebook.\n",
    "5. Copy tunnel URL & call from local client scripts.\n",
    "\n",
    "Security:\n",
    "Use a bearer token stored in `SERVICE_TOKEN` environment variable. Change the default.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92522ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install / upgrade dependencies (Kaggle often has some preinstalled)\n",
    "%pip install -q --upgrade pip\n",
    "%pip install -q fastapi uvicorn insightface opencv-python-headless pillow numpy cloudpickle\n",
    "\n",
    "import os, subprocess, sys, json, math, time\n",
    "print('Python version:', sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c358ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment configuration\n",
    "import os\n",
    "SERVICE_TOKEN = os.environ.get('SERVICE_TOKEN', 'changeme')  # CHANGE THIS\n",
    "MODEL_PACK = os.environ.get('MODEL_PACK', 'buffalo_l')\n",
    "DET_SIZE = tuple(int(x) for x in os.environ.get('DET_SIZE', '640,640').split(','))\n",
    "print({'SERVICE_TOKEN': SERVICE_TOKEN, 'MODEL_PACK': MODEL_PACK, 'DET_SIZE': DET_SIZE})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050f6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model (warm-up) to verify GPU access\n",
    "import insightface, time\n",
    "from pprint import pprint\n",
    "\n",
    "providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "print('Attempting to load FaceAnalysis with providers:', providers)\n",
    "face_app = insightface.app.FaceAnalysis(name=MODEL_PACK, providers=providers)\n",
    "face_app.prepare(ctx_id=0, det_size=DET_SIZE)\n",
    "print('Model loaded. Providers actually used:', face_app.providers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1cdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI server definition (in-notebook)\n",
    "import base64, numpy as np\n",
    "from fastapi import FastAPI, HTTPException, Depends, Header\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import uvicorn, threading\n",
    "\n",
    "app = FastAPI(title='InsightFace Remote Embedding Service', version='0.1.0')\n",
    "\n",
    "class EmbedRequest(BaseModel):\n",
    "    images: List[str]\n",
    "class EmbedResponse(BaseModel):\n",
    "    embeddings: List[List[float]]\n",
    "    count: int\n",
    "class SimilarityRequest(BaseModel):\n",
    "    emb_a: List[float]\n",
    "    emb_b: List[float]\n",
    "class SimilarityResponse(BaseModel):\n",
    "    similarity: float\n",
    "class PingResponse(BaseModel):\n",
    "    model_pack: str\n",
    "    det_size: List[int]\n",
    "    provider_list: List[str]\n",
    "\n",
    "SERVICE_TOKEN = SERVICE_TOKEN\n",
    "\n",
    "def auth_check(authorization: Optional[str] = Header(None)):\n",
    "    if not SERVICE_TOKEN:\n",
    "        return\n",
    "    if not authorization or not authorization.startswith('Bearer '):\n",
    "        raise HTTPException(status_code=401, detail='Missing bearer token')\n",
    "    if authorization.split(' ',1)[1] != SERVICE_TOKEN:\n",
    "        raise HTTPException(status_code=403, detail='Invalid token')\n",
    "\n",
    "def decode_image(b64_str: str):\n",
    "    raw = base64.b64decode(b64_str)\n",
    "    im = Image.open(BytesIO(raw)).convert('RGB')\n",
    "    import numpy as _np\n",
    "    return _np.array(im)[:, :, ::-1]\n",
    "\n",
    "@app.post('/ping', response_model=PingResponse)\n",
    "async def ping(_: None = Depends(auth_check)):\n",
    "    return PingResponse(model_pack=MODEL_PACK, det_size=list(DET_SIZE), provider_list=face_app.providers)\n",
    "\n",
    "@app.post('/embed', response_model=EmbedResponse)\n",
    "async def embed(req: EmbedRequest, _: None = Depends(auth_check)):\n",
    "    out = []\n",
    "    for img_b64 in req.images:\n",
    "        img = decode_image(img_b64)\n",
    "        faces = face_app.get(img)\n",
    "        if not faces:\n",
    "            out.append([])\n",
    "        else:\n",
    "            out.append(faces[0].normed_embedding.tolist())\n",
    "    return EmbedResponse(embeddings=out, count=len(out))\n",
    "\n",
    "@app.post('/similarity', response_model=SimilarityResponse)\n",
    "async def similarity(req: SimilarityRequest, _: None = Depends(auth_check)):\n",
    "    import numpy as _np\n",
    "    a = _np.array(req.emb_a, dtype='float32')\n",
    "    b = _np.array(req.emb_b, dtype='float32')\n",
    "    sim = float((_np.dot(a, b) / (_np.linalg.norm(a) * _np.linalg.norm(b))))\n",
    "    return SimilarityResponse(similarity=sim)\n",
    "\n",
    "# Launch server in background thread\n",
    "\n",
    "def run_server():\n",
    "    uvicorn.run(app, host='0.0.0.0', port=8000, log_level='warning')\n",
    "\n",
    "thread = threading.Thread(target=run_server, daemon=True)\n",
    "thread.start()\n",
    "print('Server thread started on port 8000.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f697b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Cloudflare tunnel\n",
    "# Kaggle usually allows outbound apt operations; if blocked skip this.\n",
    "import subprocess, textwrap, shutil, os, json, time\n",
    "if shutil.which('cloudflared') is None:\n",
    "    print('Installing cloudflared...')\n",
    "    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n",
    "    !chmod +x cloudflared\n",
    "    !mv cloudflared /usr/local/bin/\n",
    "else:\n",
    "    print('cloudflared already installed')\n",
    "\n",
    "TUNNEL_URL = None\n",
    "try:\n",
    "    proc = subprocess.Popen(['cloudflared','tunnel','--url','http://localhost:8000','--no-autoupdate'], stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "    print('Starting tunnel (wait ~5-10s)...')\n",
    "    import threading\n",
    "    lines = []\n",
    "    def reader():\n",
    "        global TUNNEL_URL\n",
    "        for line in proc.stdout:\n",
    "            if 'trycloudflare.com' in line and 'https://' in line:\n",
    "                start = line.find('https://')\n",
    "                url = line[start:].strip()\n",
    "                if ' ' in url:\n",
    "                    url = url.split(' ',1)[0]\n",
    "                TUNNEL_URL = url\n",
    "            print(line, end='')\n",
    "    t = threading.Thread(target=reader, daemon=True)\n",
    "    t.start()\n",
    "    # wait some seconds for URL\n",
    "    for _ in range(30):\n",
    "        if TUNNEL_URL:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "    if TUNNEL_URL:\n",
    "        print('Tunnel URL:', TUNNEL_URL)\n",
    "    else:\n",
    "        print('Tunnel URL not captured yet; check logs above.')\n",
    "except Exception as e:\n",
    "    print('Tunnel setup failed:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick local test of /ping endpoint\n",
    "import requests, json, os\n",
    "BASE='http://localhost:8000'\n",
    "headers={'Authorization': f'Bearer {SERVICE_TOKEN}'} if SERVICE_TOKEN else {}\n",
    "resp = requests.post(BASE+'/ping', headers=headers)\n",
    "print(resp.status_code, resp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1564481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample embed test using a tiny placeholder image (generate solid color)\n",
    "import numpy as np, base64, requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "arr = (np.ones((112,112,3))*127).astype('uint8')\n",
    "im = Image.fromarray(arr)\n",
    "buf = BytesIO(); im.save(buf, format='JPEG'); b64=base64.b64encode(buf.getvalue()).decode()\n",
    "headers={'Authorization': f'Bearer {SERVICE_TOKEN}'} if SERVICE_TOKEN else {}\n",
    "resp = requests.post('http://localhost:8000/embed', json={'images':[b64]}, headers=headers)\n",
    "print(resp.status_code, resp.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ff18f",
   "metadata": {},
   "source": [
    "## Usage From Local Machine\n",
    "\n",
    "1. Run all cells above until tunnel URL appears (if using Cloudflare). Suppose it is `https://xyz.trycloudflare.com`.\n",
    "2. On local machine export token:\n",
    "   ```bash\n",
    "   export SERVICE_TOKEN=yourtoken\n",
    "   ```\n",
    "3. Test client:\n",
    "   ```bash\n",
    "   python kaggle_pipeline/client/remote_similarity_cli.py --url https://xyz.trycloudflare.com \\\n",
    "       --ref assets/raw_face.webp --query assets/person1.webp\n",
    "   ```\n",
    "4. Integrate by modifying local detection loop to call remote embedding for each detected face instead of local model inference (optional optimization if GPU needed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feed3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch: add GET / route (if not already) and keep-alive pinger\n",
    "try:\n",
    "    from fastapi import APIRouter\n",
    "    @app.get('/')\n",
    "    def root():\n",
    "        return {\"status\":\"ok\",\"msg\":\"Use POST /ping /embed /similarity\"}\n",
    "    print('Root route added.')\n",
    "except Exception as e:\n",
    "    print('Root route patch skipped:', e)\n",
    "\n",
    "# Simple keep-alive thread to prevent idle timeouts (hits local /ping every 50s)\n",
    "import threading, time, requests, os\n",
    "if 'KEEPALIVE_STARTED' not in globals():\n",
    "    def _keepalive():\n",
    "        while True:\n",
    "            try:\n",
    "                h = {'Authorization': f'Bearer {SERVICE_TOKEN}'} if SERVICE_TOKEN else {}\n",
    "                requests.post('http://127.0.0.1:8000/ping', headers=h, timeout=5)\n",
    "            except Exception:\n",
    "                pass\n",
    "            time.sleep(50)\n",
    "    threading.Thread(target=_keepalive, daemon=True).start()\n",
    "    KEEPALIVE_STARTED = True\n",
    "    print('Keep-alive thread started.')\n",
    "else:\n",
    "    print('Keep-alive already running.')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
